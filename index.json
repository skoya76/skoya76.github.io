[{"categories":null,"contents":" Hello World A sample go program is show here.\npackage main import \u0026#34;fmt\u0026#34; func main() { message := greetMe(\u0026#34;world\u0026#34;) fmt.Println(message) } func greetMe(name string) string { return \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34; } Run the program as below:\n$ go run hello.go Variables Normal Declaration:\nvar msg string msg = \u0026#34;Hello\u0026#34; Shortcut:\nmsg := \u0026#34;Hello\u0026#34; Constants const Phi = 1.618 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/notes/go/basic/introduction/","summary":" Hello World A sample go program is show here.\npackage main import \u0026#34;fmt\u0026#34; func main() { message := greetMe(\u0026#34;world\u0026#34;) fmt.Println(message) } func greetMe(name string) string { return \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34; } Run the program as below:\n$ go run hello.go Variables Normal Declaration:\nvar msg string msg = \u0026#34;Hello\u0026#34; Shortcut:\nmsg := \u0026#34;Hello\u0026#34; Constants const Phi = 1.618 ","tags":null,"title":"Go পরিচিতি"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/notes/go/basic/_index.bn/","summary":"","tags":null,"title":"Go বেসিক"},{"categories":null,"contents":"","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/notes/go/advanced/_index.bn/","summary":"","tags":null,"title":"অ্যাডভান্সড"},{"categories":null,"contents":" Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string` Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0} Pointers func main () { b := *getPointer() fmt.Println(\u0026#34;Value is\u0026#34;, b) func getPointer () (myPointer *int) { a := 234 return \u0026amp;a a := new(int) *a = 234 Pointers point to a memory location of a variable. Go is fully garbage-collected.\nType Conversion i := 2 f := float64(i) u := uint(i) Slice slice := []int{2, 3, 4} slice := []byte(\u0026#34;Hello\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/notes/go/basic/types/","summary":"Strings str := \u0026#34;Hello\u0026#34; Multiline string\nstr := `Multiline string` Numbers Typical types\nnum := 3 // int num := 3. // float64 num := 3 + 4i // complex128 num := byte(\u0026#39;a\u0026#39;) // byte (alias for uint8) Other Types\nvar u uint = 7 // uint (unsigned) var p float32 = 22.7 // 32-bit float Arrays // var numbers [5]int numbers := [...]int{0, 0, 0, 0, 0} Pointers func main () { b := *getPointer() fmt.","tags":null,"title":"বেসিক টাইপ সমূহ"},{"categories":null,"contents":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) Switch switch day { case \u0026#34;sunday\u0026#34;: // cases don\u0026#39;t \u0026#34;fall through\u0026#34; by default! fallthrough case \u0026#34;saturday\u0026#34;: rest() default: work() } Loop for count := 0; count \u0026lt;= 10; count++ { fmt.Println(\u0026#34;My counter is at\u0026#34;, count) } entry := []string{\u0026#34;Jack\u0026#34;,\u0026#34;John\u0026#34;,\u0026#34;Jones\u0026#34;} for i, val := range entry { fmt.Printf(\u0026#34;At position %d, the character %s is present\\n\u0026#34;, i, val) n := 0 x := 42 for n != x { n := guess() } ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/notes/go/basic/flow-control/","summary":"Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) Switch switch day { case \u0026#34;sunday\u0026#34;: // cases don\u0026#39;t \u0026#34;fall through\u0026#34; by default! fallthrough case \u0026#34;saturday\u0026#34;: rest() default: work() } Loop for count := 0; count \u0026lt;= 10; count++ { fmt.Println(\u0026#34;My counter is at\u0026#34;, count) } entry := []string{\u0026#34;Jack\u0026#34;,\u0026#34;John\u0026#34;,\u0026#34;Jones\u0026#34;} for i, val := range entry { fmt.","tags":null,"title":"Flow Control"},{"categories":null,"contents":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/notes/go/advanced/files/","summary":" Condition if day == \u0026#34;sunday\u0026#34; || day == \u0026#34;saturday\u0026#34; { rest() } else if day == \u0026#34;monday\u0026#34; \u0026amp;\u0026amp; isTired() { groan() } else { work() } if _, err := doThing(); err != nil { fmt.Println(\u0026#34;Uh oh\u0026#34;) ","tags":null,"title":"ফাইল ম্যানিপুলেশন"},{"categories":null,"contents":" Variable NAME=\u0026#34;John\u0026#34; echo $NAME echo \u0026#34;$NAME\u0026#34; echo \u0026#34;${NAME} Condition if [[ -z \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is empty\u0026#34; elif [[ -n \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is not empty\u0026#34; fi ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/notes/bash/basic/","summary":" Variable NAME=\u0026#34;John\u0026#34; echo $NAME echo \u0026#34;$NAME\u0026#34; echo \u0026#34;${NAME} Condition if [[ -z \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is empty\u0026#34; elif [[ -n \u0026#34;$string\u0026#34; ]]; then echo \u0026#34;String is not empty\u0026#34; fi ","tags":null,"title":"ব্যাশ ভেরিয়েবল"},{"categories":null,"contents":"本記事はdev.toから移植しました．\nIntroduction The word \u0026ldquo;consistency\u0026rdquo; has many meanings in computer science. In this article, we will explain the various consistency aspects of distributed system replication in a clear and straightforward manner.\nSerializability State machine replication with linearizability sorts transactions into a sequence, and that sequence is guaranteed for all replicas. This is completely independent of real-world time.\nLinearizability causes the problems shown in the following figure.\nLinearizability only guarantees the update order between replicas, as shown in the figure above, and there is no way to know when that information will be transmitted to other replicas. So, it is possible to read the latest value only at the replica where the latest write was performed, but it is not guaranteed that the latest value can be read at the other replicas.\nLinearizability The difference between linearizability and serializability is always the ability to read the latest value at any replica. Linearizability allows any replica to read the latest value.\nThe following words are synonymous with linearizability.\nAtomic consistency Strong consistency Immediate Consistency External Consistency How do we achieve linearization? Linearizability wants to make the data look like one. To do so, simply lock the whole thing when updating. Therefore, guaranteeing linearizability sacrifices availability.\nEventual Consistency Eventual consistency means that if you stop writing to the database and wait for some unspecified length of time, then eventually all read requests will return the same value. This means that it is not known when updates to the database will stop, but it is guaranteed that identical values will eventually be read from all replicas. This is a very weak guarantee and says nothing about when the convergence will occur.\n","date":"September 3, 2022","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/posts/distsys/consistencies/","summary":"本記事はdev.toから移植しました．\nIntroduction The word \u0026ldquo;consistency\u0026rdquo; has many meanings in computer science. In this article, we will explain the various consistency aspects of distributed system replication in a clear and straightforward manner.\nSerializability State machine replication with linearizability sorts transactions into a sequence, and that sequence is guaranteed for all replicas. This is completely independent of real-world time.\nLinearizability causes the problems shown in the following figure.\nLinearizability only guarantees the update order between replicas, as shown in the figure above, and there is no way to know when that information will be transmitted to other replicas.","tags":null,"title":"Various Consistencies"},{"categories":null,"contents":"本記事はdev.toから移植しました．\nIntroduction The previous article explained the communication model for the timing of consensus problem. In this article, we will introduce four general definitions of failure models for consensus problem nodes.\nCrash-stop faults This model only places the assumption that the node will Crash-stop faults. Also, a node that is stopped in this model never comes back.\nOmission faults This model assumes Crash-stop faults and Omission faults. Omission faults may or may not reply to messages. This ignoring cannot be judged by other nodes as to whether it is Crash-stop faults or Omission faults.\nCrash-recovery faults This model assumes Crash-stop faults, Omission faults, and Crash-recovery faults. The crash recovery fault makes the assumption that a node may crash at any time and may begin to re-intervene with the response at any time. The model also assumes partial data loss due to crash. If there is no response from a node in this model, it is not possible to determine whether it is Crash-stop faults, Omission faults, or Crash-recovery faults.\nByzantine faults This model assumes Crash-stop faults, Omission faults, Crash-recovery faults, and Byzantine faults. Byzantine breakdowns can do whatever the node does. For example, it can ignore messages, it can pretend to be malfunctioning, can reply to fake messages, or it can do evil deeds jointly among multiple Byzantine failure nodes.\nConclusion The difficulty of dealing with each failure model is illustrated in the figure below.\nIn other words, the Byzantine failure model is the most difficult assumption to deal with.\n","date":"August 22, 2022","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/posts/distsys/failuremodels/","summary":"本記事はdev.toから移植しました．\nIntroduction The previous article explained the communication model for the timing of consensus problem. In this article, we will introduce four general definitions of failure models for consensus problem nodes.\nCrash-stop faults This model only places the assumption that the node will Crash-stop faults. Also, a node that is stopped in this model never comes back.\nOmission faults This model assumes Crash-stop faults and Omission faults. Omission faults may or may not reply to messages.","tags":null,"title":"Failure Models"},{"categories":null,"contents":"本記事はdev.toから移植しました．\nIntroduction In a standard distributed computing environment, the presence of message-delaying attackers (Communication delays or failures) introduces communication uncertainty. Three communication models are broadly defined for the distributed systems consensus problem.\nSynchronous Communication model The synchronous model defines a known finite time range ⊿ for message delivery, and an attacker can only cause a delay of at most ⊿ in the delivery of a message. In other words, when a sender sends a message, it is guaranteed to be received by the other party within a certain time ⊿. This ⊿ is known to all participants.\nIn real systems, this synchronization model is impractical. The reason for this is that there is known to be no upper bound on delays and temporary failures.\nAsynchronous Communication model In the asynchronous model, only final delivery is guaranteed for message delivery, and an attacker can delay message delivery for any finite amount of time.\nThis asynchronous model does not allow for any assumptions to be made in the consensus algorithm. Some consensus algorithms are available for the asynchronous model, but they have very strict restrictions.\nPartial synchronous communication model The partial synchronous model lies between the synchronous and asynchronous models. In addition to the known finite time range ⊿, there is an event called GST (global stabilization time). In the partial synchronous model, a message sent at time t will be stabilized at time max(x,GST)+⊿. In other words, the system operates in the asynchronous model up to GST and in the synchronous model after GST. The GST event must occur after an unknown finite time for the attack.\nIn other words, this partial synchronization model behaves the same as the synchronization model in most cases. However, sometimes network delays, temporary failures, or clock errors mean that the upper bound is exceeded. We do not know how long the network will wait if network delays, temporary failures, or clock errors occur (equal to the asynchronous model).\n","date":"August 21, 2022","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/posts/distsys/communicationmodels/","summary":"本記事はdev.toから移植しました．\nIntroduction In a standard distributed computing environment, the presence of message-delaying attackers (Communication delays or failures) introduces communication uncertainty. Three communication models are broadly defined for the distributed systems consensus problem.\nSynchronous Communication model The synchronous model defines a known finite time range ⊿ for message delivery, and an attacker can only cause a delay of at most ⊿ in the delivery of a message. In other words, when a sender sends a message, it is guaranteed to be received by the other party within a certain time ⊿.","tags":null,"title":"Communication Models"},{"categories":null,"contents":"本記事はdev.toから移植しました．\nIntroduction Lamport timestamp is a method proposed by Leslie Lamport for generating sequence numbers that are consistent with a causality law.\nLamport timestamp Each node (replica) is assigned a unique ID. (counter, NodeID) is the timestamp If the counters have the same value, the one with the larger node ID is considered the larger timestamp. (3,2) \u0026lt; (3,5) When a node generates a timestamp, it compares the largest value it is aware of with the client\u0026rsquo;s value and sets the larger value as the timestamp counter value. The figure below shows a concrete example of a Lamport timestamp.\nThe order of execution in the above diagram is as follows.\n(1,1)\u0026lt;(1,2)\u0026lt;(2,1)\u0026lt;(2,2)\u0026lt;(3,1)\u0026lt;(4,1)\u0026lt;(5,1)\u0026lt;(5,2)\nComparing this sequence with the figure shows that real time and the time line do not match. For example, in real time, (3,1) \u0026lt; (2,2) and (5,2) \u0026lt; (5,1), but in reverse order in the Lamport timestamps.\nWhy is this so? That is because the Lamport timestamp is always intended to define the entire sequence. In other words, Lamport timestamp cannot identify whether two operations were performed in parallel or causally dependent. Because of this, it is designed to be more compact than the version vector.\n","date":"August 20, 2022","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/posts/distsys/timestamp/","summary":"本記事はdev.toから移植しました．\nIntroduction Lamport timestamp is a method proposed by Leslie Lamport for generating sequence numbers that are consistent with a causality law.\nLamport timestamp Each node (replica) is assigned a unique ID. (counter, NodeID) is the timestamp If the counters have the same value, the one with the larger node ID is considered the larger timestamp. (3,2) \u0026lt; (3,5) When a node generates a timestamp, it compares the largest value it is aware of with the client\u0026rsquo;s value and sets the larger value as the timestamp counter value.","tags":null,"title":"Lamport Timestamp"},{"categories":null,"contents":"本記事はdev.toから移植しました．\nWhat is Total order? The way to determine if a given element is in total order is simple. That is, \u0026ldquo;Can you put those elements in a row?\u0026rdquo;.\nFor example, what if the natural numbers 7, 8, 1, 4, and 5 are given? We can then serialize 1\u0026lt;4\u0026lt;5\u0026lt;7\u0026lt;8. In other words, the natural numbers are total order.\nWhat about the sets {b, d}, {d,d} {z, b} next? They cannot be serialized. In other words, these sets are not in total order.\nState machine replication requires the total order of operations.\nHow to Total order operations? 1. Logical clock The idea behind the logical clock is simple. For each operation, a counter is incremented and its number is included in the operation information. Each replica applies operations in the ascending order of that counter.\nFor example, suppose that the operations are issued in the order op_A, op_B, and op_C. Then cnt (op_A) = 0, cnt (op_B) = 1, and cnt (op_C) = 2 are given. The replica applies the operations according to that number in the order op_A, op_B, and op_C.\nThis can be accomplished by installing a leader replica. All operations are communicated to the leader. This allows the leader to assign a counter number to the operation. All replicas can then apply the operations according to that number to guarantee total order.\nThere are situations, however, in which it is not desirable to implement a single leader. How can we ensure total order then?\n2. Lamport timestamp This is explained in detail in another article by me. As explained in this article, the total order guaranteed by the Lamport timestamp may not be sufficient. For example, suppose that operations are issued to create identical usernames on different nodes. However, the usernames must be unique. In this case, one might think that the one with the smaller timestamp (the write created first) should win. But is that instantly possible? We don\u0026rsquo;t know if there is another account with the same username being created in parallel on another node, whose timestamp may or may not be larger than the timestamp we are trying to win. In other words, the full order of operations will only be determined after we have information on all the nodes.\nTherefore, to implement the unique constraint, the total order of operations is not sufficient, and the total order broadcast described below is needed to know the definite time of the total order.\nTotal order broadcast There are two safety concerns that total order broadcasts must satisfy.\nMessages are not lost. Messages received by any node are always received by all nodes. Messages must be conveyed to all nodes in the same order. Different order is not allowed as shown in the following figure. The following image shows an example of a successful total order broad. What makes it difficult? At first glance, a total order broadcast seems simple. However, it becomes difficult when using an asynchronous communication model. See my article on various communication models for distributed systems.\nThe asynchronous communication model has the following characteristics\nMessages are eventually delivered. Messages can be delayed with no upper limit. Message arrival order not guaranteed. In other words, using the asynchronous communication model causes the problems shown in the following figure.\nIn other words, the order of arrival of messages may change if nothing is done under a delay environment. This does not adhere to the principle of total order broadcast.\nSolution The solution is simple. First, the replica that wants to deliver a message broadcasts that message. In addition, the replica that receives the message broadcasts an \u0026ldquo;ack\u0026rdquo;. If all replicas agree, the message can be logged locally. This is illustrated in the following figure. The order relationship between m1 and m2 is m1 \u0026lt; m2.\nThe wait in the figure above indicates that it is waiting for m1 to agree. This is because if m2 is logged before m1, the order relationship is broken.\nComment This article introduced a simple all-order broadcast. However, frequent broadcasts are undesirable from the standpoint of communication volume. Therefore, new protocols with reduced communication costs, such as FastPaxos, have been developed.\nThank you for reading to the end!\n","date":"August 20, 2022","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/posts/distsys/tob/","summary":"本記事はdev.toから移植しました．\nWhat is Total order? The way to determine if a given element is in total order is simple. That is, \u0026ldquo;Can you put those elements in a row?\u0026rdquo;.\nFor example, what if the natural numbers 7, 8, 1, 4, and 5 are given? We can then serialize 1\u0026lt;4\u0026lt;5\u0026lt;7\u0026lt;8. In other words, the natural numbers are total order.\nWhat about the sets {b, d}, {d,d} {z, b} next? They cannot be serialized.","tags":null,"title":"Total Order Broadcast"},{"categories":null,"contents":"本記事はdev.toから移植しました．\nIntroduction In computer science, state machine replication (SMR) or state machine approach is a general method for implementing a fault-tolerant service by replicating servers and coordinating client interactions with server replicas. The approach also provides a framework for understanding and designing replication management protocols [Wikipedia].\nWhat is Fault-tolerant? Fault tolerance is simply the property that guarantees the provision of service without problems even if some of the replicated copies break down.\nType of failure There are many reasons why a server may not be able to provide service. For example, human error, natural disasters, and machine failure. These failures are referred to as Fail-Stop that simply cannot be serviced.\nApart from fail stops, there is Byzantine Failure. Byzantine failure is easier to understand if you simply imagine that a node has been hijacked. In other words, with a stop failure, if you send a message after the failure, you will not receive a reply (because you did nothing). But with a Byzantine failure, if you message it, it may send you a fake message, or it may ignore you and make it look like it is stopped. Also, multiple Byzantine nodes might cooperate to do bad things.\nHow many failures are tolerated? First, consider a stop fault. Look at the image below. This situation has N=3 and F=1. Node B is stopped. In other words, there is no response when a message is sent to node B. In this case, node A and node C can check with each other to find the correct value. Let\u0026rsquo;s take the idea further. If node A stops, then node C has no way to determine if its value is correct. In other words, if N=3, we know that it will not work well if F more than 1. In summary, the required condition for assuming only stop faults is (N \u0026gt;= 2F + 1).\nNext, we will deal with Byzantine failure. What if node B in the image above is a Byzantine failure? In that case, when node A wants to check the consistency of the values, it checks node B and node C for the values from them. However, node B may send a false message because of a Byzantine fault. In other words, node A cannot determine the value if it receives two different values. This is the same from the standpoint of node C. In other words, assuming Byzantine failure, N=3 and F=1 are not sufficient.\nLook at the image below.\nThis situation has N=4 and F=1. This situation is also the same, with node B having a Byzantine failure and all other nodes normal. In this case, even if node A receives a false value from the Byzantine node, it can still determine which is the correct value by majority vote if it receives the correct values from the other two normal nodes. In summary, the required condition for assuming Byzantine faults is (N \u0026gt;= 3F + 1).\nState machine Approach The following is from [Wikipedia].\nPlace copies of the State Machine on multiple, independent servers. Receive client requests, interpreted as Inputs to the State Machine. Choose an ordering for the Inputs. Execute Inputs in the chosen order on each server. Respond to clients with the Output from the State Machine. Monitor replicas for differences in State or Output. Specific examples are shown below. The blue circles indicate the servers (replicas) that make up the state machine replicas. The arrows indicate that an update request occurred to the replicas indicated by the arrows in the order of their numbers.\nIn this case, if the process is successful, all updates will be performed in the same order in all replicas, as shown in the image below.\nComment In this article, state machine replication was explained. It is easy to imagine that the number of messages exchanged between replicas would be enormous in order for all replicas to perform the update process in the same order. For this reason, research is still being conducted on protocols to reduce the communication cost of state machine replication. Examples include Fast Paxos, EPaxos, and Mencius. Please look forward to my future explanation of these as well.\nThank you for reading to the end.\n","date":"August 19, 2022","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/posts/distsys/smr/","summary":"本記事はdev.toから移植しました．\nIntroduction In computer science, state machine replication (SMR) or state machine approach is a general method for implementing a fault-tolerant service by replicating servers and coordinating client interactions with server replicas. The approach also provides a framework for understanding and designing replication management protocols [Wikipedia].\nWhat is Fault-tolerant? Fault tolerance is simply the property that guarantees the provision of service without problems even if some of the replicated copies break down.","tags":null,"title":"State Machine Replication"},{"categories":null,"contents":"本記事はdev.toから移植しました．\nIntroduction In my last article, I wrote about Paxos (What is Paxos?). Paxos could only determine a single value. Nothing more, nothing less.\nSMR and Total Order Broadcast SMR (State machine replication) is a method of achieving fault-tolerant service by replicating servers and having those servers cooperate. All replicated servers (replicas) have exact copies. This allows for improved availability by allowing a replacement replica to provide service in the event of a failure of one of the replicas.\nHowever, all replicas must apply the operations in the same order to operate to keep the replicas in the same state as each other. To accomplish this, total order broadcast is used. And Multi-Paxos, which we will discuss in this article, is used for all-order broadcasts.\nMulti-Paxos As mentioned above, Multi-Paxos wants to agree on the order of execution of instructions. The figure below shows an illustration of Paxos and Multi-Paxos. The Paxos figure depicts a single value being determined by all participants. The Multi-Paxos figure depicts a blue replica as the leader, and multiple values are determined by consensus. The leader serializes the execution of each Paxos.\nTo accomplish this, include the proposal number used by Paxos and the i in the index number of the i-th order in the message to be transacted in each request.\nComment Leader changes and other detailed specifications are in this paper.\nThanks for reading to the end!\n","date":"August 18, 2022","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/posts/distsys/multipaxos/","summary":"本記事はdev.toから移植しました．\nIntroduction In my last article, I wrote about Paxos (What is Paxos?). Paxos could only determine a single value. Nothing more, nothing less.\nSMR and Total Order Broadcast SMR (State machine replication) is a method of achieving fault-tolerant service by replicating servers and having those servers cooperate. All replicated servers (replicas) have exact copies. This allows for improved availability by allowing a replacement replica to provide service in the event of a failure of one of the replicas.","tags":null,"title":"What is the MultiPaxos?"},{"categories":null,"contents":"本記事はdev.toから移植しました．\nIntroduction Paxos is a consensus algorithm in distributed systems. The consensus algorithm is an algorithm that determines (agrees on) a single value within a network of multiple nodes.\nPaxos wants to do In a phrase, Paxos wants to determine a single value that will not be overturned. Specifically, computers that are independent of each other (do not share memory) and exchange information only through the network participate in the consensus, and if a majority of them choose the same value, them all learn that value and it cannot be overturned.\nWhy is it difficult to get Consensus? Paxos is desigined to work well even if communication massages are lost or computers fail. Therefore, if a communication parther does not reply to a message, it is impossible to determine whether the communication is slow, the parthner is malfunctioning, or the message has been lost. This is called the asyncronous communication model in distributed systems.\nPaxos algorithm The algorithm is difficult to understand. That\u0026rsquo;s why we deal with specific examples. Look at the following images Captuer of Youtube Video. Phase1 -a When the value proposer wants to decide on a value, a Propose message is sent to everyone.This is assigned a monotonically increasing proposal number.\nPhase1 -b The acceptor checks the current received proposal number and the maximum proposal number it has received in the past. If the current received proposal number is larger, the acceptor takes one of the following actions\n① If there is no previously accepted value, the proposer replies prepare message.\n② If there is already another accepted value, reply with a received message including that value.\nPhase2 -a ① If a prepare message is received from an acceptor, the proposer sends an acceptance request of any value to that acceptor.\n② If a received message is received, check the previously received values contained in that message. It then overwrites the value the proposer wishes to propose with that value and sends a request for acceptance of that value.\nPhase2 -b The acceptor learns the values sent by the proposer.\nComment As we have described, the Paxos algorithm can be used to determine a single uncovered value among distributed nodes connected by an asynchronous channel. This underlying algorithm is the basis for such algorithms as Multi-Paxos, which determines the order of execution of state machine replications (SMRs).\nThanks for reading all the way to the end!\n","date":"August 17, 2022","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/posts/distsys/paxos/","summary":"本記事はdev.toから移植しました．\nIntroduction Paxos is a consensus algorithm in distributed systems. The consensus algorithm is an algorithm that determines (agrees on) a single value within a network of multiple nodes.\nPaxos wants to do In a phrase, Paxos wants to determine a single value that will not be overturned. Specifically, computers that are independent of each other (do not share memory) and exchange information only through the network participate in the consensus, and if a majority of them choose the same value, them all learn that value and it cannot be overturned.","tags":null,"title":"What is the Paxos?"},{"categories":null,"contents":"","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/notes/_index.bn/","summary":"","tags":null,"title":"নোট সমূহ"},{"categories":null,"contents":"Go Notes ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/notes/go/_index.bn/","summary":"Go Notes ","tags":null,"title":"Go এর নোট সমূহ"},{"categories":null,"contents":"．．．\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/posts/internship/kag/","summary":"．．．","tags":null,"title":"KAGのインターンに参加したお話"},{"categories":null,"contents":"Bash Notes ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/notes/bash/_index.bn/","summary":"Bash Notes ","tags":null,"title":"ব্যাশের নোট সমূহ"},{"categories":null,"contents":"なぜ参加しようとおもったか 選考に関して スケジュールと内容 感想 ","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/posts/internship/rakuten/","summary":"なぜ参加しようとおもったか 選考に関して スケジュールと内容 感想 ","tags":null,"title":"楽天のインターンに参加したお話"},{"categories":null,"contents":"．．．\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://skoya76.github.io/posts/internship/toray/","summary":"．．．","tags":null,"title":"海外インターン（東レ）に参加したお話"}]